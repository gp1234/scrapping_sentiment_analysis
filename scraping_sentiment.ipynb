{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping and Sentiment Analysis example\n",
    "In the code snippet provided, the following actions are performed:\n",
    "\n",
    "1. The necessary modules are imported: `requests`, `re`, and `BeautifulSoup` from the `bs4` library.\n",
    "2. A function named `scrape_data` is defined. This function takes a URL as input and performs web scraping to extract data from the webpage.\n",
    "3. Inside the `scrape_data` function, a user agent header is set to mimic a web browser.\n",
    "4. A GET request is made to the specified URL using the `requests.get()` method, along with the headers.\n",
    "5. The response is parsed using BeautifulSoup with the \"html.parser\" parser.\n",
    "6. The function finds all the \"ul\" elements with the class \"feed-chronology\" and stores them in the `lastest_news` variable.\n",
    "7. A loop iterates over each news item and extracts the links.\n",
    "8. The extracted links are appended to the `links_arr` list after modifying them to include the base URL.\n",
    "9. Another GET request is made to the first link in the `links_arr` list.\n",
    "10. The response is parsed using BeautifulSoup.\n",
    "11. The function finds all the \"p\" elements with the class \"prose-text\" and stores them in the `content` variable.\n",
    "12. The text content of each \"p\" element is concatenated and stored in the `text_to_analyze` variable.\n",
    "13. Finally, the `text_to_analyze` variable is returned as the result of the `scrape_data` function.\n",
    "\n",
    "Below the code snippet, the `scrape_data` function is called with the URL _blank to scrape data from that webpage. The extracted text is assigned to the `text_to_analyze` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "def scrape_data(url):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    results = BeautifulSoup(response.text, \"html.parser\")\n",
    "    lastest_news = results.find_all(\"ul\", class_=\"feed-chronology\")\n",
    "    for news in lastest_news:\n",
    "        links = news.findAll(\"a\")\n",
    "    links_arr = []\n",
    "    for link in links:\n",
    "         links_arr.append(re.sub(r\"/$\", \"\", url) + link.get(\"href\"))\n",
    "    response_2 = requests.get(links_arr[0], headers=headers)\n",
    "    results_2 = BeautifulSoup(response_2.text, \"html.parser\")\n",
    "    content = results_2.find_all(\"p\", class_=\"prose-text\")\n",
    "    text_to_analyze = \"\"\n",
    "    for c in content:\n",
    "        text_to_analyze += c.text\n",
    "    return text_to_analyze\n",
    "text_to_analyze = scrape_data(\"url\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code snippet provided, the following actions are performed:\n",
    "\n",
    "1. The necessary modules are imported: `openai` and `load_dotenv` from the `dotenv` library, and `os`.\n",
    "2. The `load_dotenv` function is used to load environment variables from a `.env` file.\n",
    "3. The `secret_key` variable is assigned the value of the environment variable named \"secret_key\" using `os.getenv()`.\n",
    "4. The OpenAI API key is set using the `api_key` attribute of the `openai` module.\n",
    "5. The `analyze_sentiment` function is defined. This function takes a text as input and performs sentiment analysis using the OpenAI completion API.\n",
    "6. Inside the `analyze_sentiment` function, a prompt is defined as \"This is a sentiment analysis task. The sentiment of the following text is:\".\n",
    "7. The input text is constructed by concatenating the prompt and the provided text.\n",
    "8. The OpenAI completion request is set up using the `openai.Completion.create()` method. The parameters include the engine, prompt, temperature, max_tokens, top_p, frequency_penalty, presence_penalty, and stop tokens.\n",
    "9. The completion response is obtained, and the sentiment label is extracted from the response.\n",
    "10. The sentiment label is returned as the result of the `analyze_sentiment` function.\n",
    "11. Below the code snippet, an example usage is shown. The `text` variable is assigned the value of `text_to_analyze`, which is the extracted text from web scraping.\n",
    "12. The `analyze_sentiment` function is called with the `text` variable as input, and the sentiment label is assigned to the `sentiment` variable.\n",
    "13. Finally, the sentiment label is printed.\n",
    "\n",
    "This code snippet demonstrates how to perform sentiment analysis using the OpenAI completion API by providing a prompt and input text. The sentiment label is then extracted from the completion response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/giovannipoveda/scrapping/library.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Example usage\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m text \u001b[39m=\u001b[39m text_to_analyze\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m sentiment \u001b[39m=\u001b[39m analyze_sentiment(text)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(sentiment)\n",
      "\u001b[1;32m/Users/giovannipoveda/scrapping/library.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m input_text \u001b[39m=\u001b[39m prompt \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mI love pizza\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Set up the OpenAI completion request\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-davinci-002\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     prompt\u001b[39m=\u001b[39;49minput_text,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     stop\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Get the sentiment label from the completion response\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/giovannipoveda/scrapping/library.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m sentiment_label \u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/miniconda3/envs/scraping_environment/lib/python3.8/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/envs/scraping_environment/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/envs/scraping_environment/lib/python3.8/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/envs/scraping_environment/lib/python3.8/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/scraping_environment/lib/python3.8/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "secret_key = os.getenv('secret_key')\n",
    "\n",
    "# Set up OpenAI connection\n",
    "openai.api_key = secret_key\n",
    "\n",
    "# Perform sentiment analysis\n",
    "def analyze_sentiment(text):\n",
    "    prompt = \"This is a sentiment analysis task. The sentiment of the following text is:\"\n",
    "\n",
    "    # Concatenate the prompt and text\n",
    "    input_text = prompt + \"\\n\" + \"I love pizza\"\n",
    "\n",
    "    # Set up the OpenAI completion request\n",
    "    completion = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=input_text,\n",
    "        temperature=0.5,\n",
    "        max_tokens=1,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=[\"\\n\"]\n",
    "    )\n",
    "\n",
    "    # Get the sentiment label from the completion response\n",
    "    sentiment_label = completion.choices[0].text.strip()\n",
    "\n",
    "    return sentiment_label\n",
    "\n",
    "# Example usage\n",
    "text = text_to_analyze\n",
    "sentiment = analyze_sentiment(text)\n",
    "print(sentiment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
